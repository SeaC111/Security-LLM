<div class="detail_content markdown-body editormd-preview-container" id="markdown-body">
<div id="app">
<h2 data-content="1" id="e1bd998260073a8a6c93001cdcf7b747">关于OpenSOC</h2>
<p>OpenSOC是思科在BroCON大会上亮相了的一个安全大数据分析架构，它是一个针对网络包和流的大数据分析框架，它是大数据分析与安全分析技术的结合, 能够实时的检测网络异常情况并且可以扩展很多节点，它的存储使用开源项目Hadoop，实时索引使用开源项目ElasticSearch，在线流分析使用著名的开源项目Storm。</p>
<p>但是其部署上和使用上可能对于大部分中小企业来说，消耗的资源和精力可能有点过于庞大。本文着重介绍如何轻量级实现OpenSOC框架，即使日后升级或者添加了SEIM也可以快速迁入。</p>
<h2 data-content="1" id="5b69f5cdd1a11669f8ff59429c3d88b1">OpenSOC介绍</h2>
<p>我们先来看一下 OpenSOC 框架</p>
<p><img src="https://xzfile.aliyuncs.com/media/upload/picture/20180321172304-757d248e-2ce9-1.png"/></p>
<h3 data-content="1" id="4ee4eee343e0f39194a6929a578411d4">OpenSOC框架组成</h3>
<p>OpenSOC框架主要包括六个部分</p>
<ul>
<li>数据来源（Source Systems）</li>
<li>数据收集（Data Collection）</li>
<li>消息通知（Messaging System）</li>
<li>实时处理（Real Time Processing）</li>
<li>数据存储（Storage）</li>
<li>访问接口（Access）</li>
</ul>
<h3 data-content="1" id="a5ed5c42a9d4305925c26b3b82b26912">OpenSOC的工作流程：</h3>
<p><strong>数据收集组件</strong>从<strong>数据来源</strong>收集日志等数据然后推送到<strong>消息通知组件</strong>，</p>
<p>通过<strong>消息通知组件</strong>分发给对应的<strong>实时处理组件</strong></p>
<p>由<strong>实时处理组件</strong>处理完后保存到<strong>数据存储组件</strong>中</p>
<p>最后由<strong>访问接口</strong>提供的API或者UI等供给用户查看或者调用</p>
<h2 data-content="1" id="e61a12c7300fe5b22efbfa0aead7c368">构建OpenSOC</h2>
<h3 data-content="1" id="e9af077106313c047a5d820832264ee7">使用的场景</h3>
<p>本文将根据以下场景来构建OpenSOC。</p>
<ul>
<li>
<p>有多台Centos的WEB服务器</p>
</li>
<li>
<p>需要获取所有的WEB服务器的访问日志</p>
</li>
<li>
<p>推送到后台的规则匹配和机器学习分析部分</p>
</li>
<li>
<p>用来判断和显示当前的访问情况</p>
</li>
</ul>
<p><strong>注：</strong>如果有其他的数据源，配置好数据收集组件进行收集即可</p>
<p>此处只针对大部分的日志文件进行推送和处理，</p>
<h3 data-content="1" id="938775fb5bc2a70b0f8bba89a835d0d7">工具和架构</h3>
<p>由于是轻量级的框架，所以在架构上会稍微调整。</p>
<ul>
<li>数据来源（/var/log/httpd/*_log） <ul>
<li>这里收集的是web服务器的日志。有其他的日志也是同样处理 </li>
</ul>
</li>
<li>数据收集 <ul>
<li>这里采用了Filebeat 一个轻量级的数据收集器</li>
<li>感兴趣的也可以用logstash，不过性能损耗比Filebeat多</li>
</ul>
</li>
<li>消息通知 <ul>
<li>这里可以选择的很多 kafka，logstash </li>
<li>但是由于轻量级 我们直接使用 Filebeat的推送   </li>
</ul>
</li>
<li>实时处理 <ul>
<li>这里调用python写的处理脚本<ul>
<li>正则处理脚本 </li>
<li>机器学习模型  </li>
</ul>
</li>
</ul>
</li>
<li>
<p>数据存储</p>
<ul>
<li>实时存储 Elasticsearch  <ul>
<li>保存日志源记录 </li>
</ul>
</li>
<li>结果存储 mysql <ul>
<li>分析的结果 </li>
<li>预先规则</li>
<li>其他配置信息</li>
</ul>
</li>
</ul>
</li>
<li>
<p>接口和展示</p>
<ul>
<li>flask写的一个简易管理后台 </li>
</ul>
</li>
</ul>
<p>整个系统结构如图：</p>
<p><img src="https://xzfile.aliyuncs.com/media/upload/picture/20180321172322-8066a0c8-2ce9-1.png"/></p>
<h2 data-content="1" id="f3324ea686a9fa9e41945de307acc086">搭建步骤</h2>
<h3 data-content="1" id="f99c26e3f9c1fa546a2db4ddc6a7ac18">数据源</h3>
<ul>
<li>使用的服务器是centos6.9 </li>
<li>直接安装 php apache mysql等</li>
<li>开启日志记录 </li>
<li>安装web应用<ul>
<li>dvwa</li>
<li>phpmyadmin</li>
<li>...等</li>
</ul>
</li>
</ul>
<h3 data-content="1" id="9d3063f6d0cec013d5b8a18f0368fab9">日志数据采集收集和推送</h3>
<ul>
<li>使用RPM安装FileBeat(Elasticseach的安装也是一样)</li>
<li>导入 rpm --import <a href="https://artifacts.elastic.co/GPG-KEY-elasticsearch" target="_blank">https://artifacts.elastic.co/GPG-KEY-elasticsearch</a>
</li>
<li>编辑  elasticsearch.repo</li>
</ul>
<pre><code>[elasticsearch-6.x]
    name=Elasticsearch repository for 6.x packages
    baseurl=https://artifacts.elastic.co/packages/6.x/yum
    gpgcheck=1
    gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
    enabled=1
    autorefresh=1
    type=rpm-md</code></pre>
<ul>
<li>yum install filebeat -y</li>
</ul>
<h3 data-content="1" id="9e55f8837226d9b4a8ef54582919fb28">安装elasticsearch</h3>
<ul>
<li>yum install elasticsearch -y</li>
</ul>
<h3 data-content="1" id="513b1b084c1521dd0590eb4297d78348">配置filebeat和elasticsearch</h3>
<ul>
<li>vi  /etc/filebeat/filebeat.yml #给filebeat添加数据源</li>
</ul>
<pre><code>filebeat.prospectors:
- input_type: log
  paths: /var/log/httpd/access_log
output.elasticsearch:
   hosts: ["IP:PORT"]</code></pre>
<ul>
<li>
<p>vi  /etc/filebeat/filebeat.yml #给filebeat添加数据源</p>
</li>
<li>
<p>vi /etc/elasticsearch/elasticsearch.yml</p>
<ul>
<li>添加 network.bind_host: 你的IP</li>
</ul>
</li>
<li>
<p>访问一下一下刚才部署的网站</p>
</li>
<li>
<p>访问 elastcisearch/_cat/indices?v 查看是否有 <strong>filebeat-**</strong> 索引建成</p>
</li>
</ul>
<p><img src="https://xzfile.aliyuncs.com/media/upload/picture/20180321170627-23630e18-2ce7-1.png"/></p>
<ul>
<li>访问 elastcisearch/filebeat-<strong>*</strong>/_search  查看刚才的访问记录是否已经同步到elastic search</li>
</ul>
<p><img src="https://xzfile.aliyuncs.com/media/upload/picture/20180321170958-a146bca8-2ce7-1.png"/></p>
<h3 data-content="1" id="410c037626c8bb5b122debd2f8445678">[注]</h3>
<ul>
<li>
<p>filebeat的paths 可以添加多个</p>
</li>
<li>
<p>支持的类型具体可以自行查看filebeat的官方文档</p>
</li>
</ul>
<h3 data-content="1" id="c77330e23d39dc159d4a981401f8bf4f">分析和展示的UI</h3>
<p>这里涉及的基本就是常规的网页编写和操作了。这里不具体展开。<br/>
大概说一下我写的思路和用到的组件</p>
<ul>
<li>分析<ul>
<li>写了日志文件 每10分钟调用一次脚本 load.py</li>
<li>脚本先判断数据是否有更新 有的话 调用分析的脚本 re_ana.py 和 knn_ana.py</li>
<li>正则是  re_ana.py  <ul>
<li>正则的规则存储在mysql中，通过人工添加 </li>
</ul>
</li>
<li>机器学习是 knn_ana.py<ul>
<li>根据正则分析出来的数据 进行学习 学习完后 再去对新的数据进行分析  </li>
</ul>
</li>
<li>机器学习的模型用了最简单的分词+KNN去使用 </li>
<li>为了降低分词带来的重复性很高的问题 添加了一个停用词表</li>
</ul>
</li>
<li>UI<ul>
<li>用FLASK编写 </li>
<li>模版用了elaadmin </li>
</ul>
</li>
</ul>
<h2 data-content="1" id="b2573e7df237bf251a99e7adbbb28112">最后效果如图</h2>
<p><img src="https://xzfile.aliyuncs.com/media/upload/picture/20180321165351-60e85fc4-2ce5-1.png"/></p>
<p>基础的OpenSoc框架搭建完成，下一篇会介绍一下</p>
<ul>
<li>正则和机器学习的准确率比较</li>
<li>我编写的一个简单的机器学习的模型</li>
<li>如何低成本的搭建蜜罐和opensoc构建威胁情报 *（这个估计还会延后，资金不够）</li>
</ul>
</div>
</div>